{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Copyright April 1. 2018, Warren E. Agin\n",
    "#Code released under the Creative Commons Attribution-NonCommercial-\n",
    "#ShareAlike 4.0 International License. You may obtain a copy of the license at \n",
    "#https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_URL = ''\n",
    "FEATURE_NAMES = 'featureNames.csv'\n",
    "TRAINING_FILE = 'trainingFile.csv'\n",
    "TRAINING_URL = '%s/%s' % (DATA_URL, TRAINING_FILE)\n",
    "EVAL_FILE1 = 'test1File.csv'\n",
    "EVAL_FILE2 = 'test2File.csv'\n",
    "EVAL_FILE3 = 'test3File.csv'\n",
    "EVAL_URL = '%s/%s' % (DATA_URL, EVAL_FILE)\n",
    "DELETED_FEATURES = [\n",
    "    'REALPROPVALUESQR',\n",
    "    'REALPROPVALUELOG',\n",
    "    'PERSPROPVALUESQR',\n",
    "    'PERSPROPVALUELOG',\n",
    "    'UNSECNPRVALUESQR',\n",
    "    'UNSECNPRVALUELOG',\n",
    "    'UNSECPRVALUESQR',\n",
    "    'UNSECPRVALUELOG',\n",
    "    'AVGMNTHIVALUESQR',\n",
    "    'AVGMNTHIVALUELOG',\n",
    "    'NTRDBT',\n",
    "#    'JOINT',\n",
    "#    'ORGD1FPRSE',\n",
    "#    'PRFILE',\n",
    "#    'DISTSUCCESS',\n",
    "    'FEEP',\n",
    "#    'FEEI',\n",
    "    'FEEW',\n",
    "    'REALPROPNULL',\n",
    "#    'REALPROPNONE',\n",
    "#    'REALPROPVALUE',\n",
    "    'PERSPROPNULL',\n",
    "#    'PERSPROPVALUE',\n",
    "#    'UNSECNPRNULL',\n",
    "#    'UNSECNPRVALUE',\n",
    "    'UNSECEXCESS',\n",
    "    'UNSECPRNULL',\n",
    "#    'UNSECPRVALUE',\n",
    "    'AVGMNTHINULL',\n",
    "#    'AVGMNTHIVALUE',\n",
    "#    'IEINDEX',\n",
    "#    'IEGAP'\n",
    "]\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read training and test sets into panda arrays\n",
    "features = pd.read_csv(FEATURE_NAMES)\n",
    "featureNames = list(features.columns)\n",
    "training = pd.read_csv(TRAINING_FILE, names=featureNames)\n",
    "testing = pd.read_csv(EVAL_FILE, names=featureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#commands to explore data - optional to run\n",
    "training.head(5)\n",
    "print('The shape of our features is:', training.shape)  #shape of training file\n",
    "training.describe()  #basic stastistics for different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert the panda arrays to numpy arrays for use with the learner\n",
    "#creates training and testing as numpy arrays, trainingLabels and testLabels as numpy\n",
    "#arrays holding the success field, and featureNames as a list of the features\n",
    "\n",
    "def removeFeatures(file):\n",
    "    for each in DELETED_FEATURES:\n",
    "        file=file.drop(each, axis=1)\n",
    "    return(file)\n",
    "\n",
    "def convert2np(file):   \n",
    "    labels = np.array(file['SUCCESS'])   #copy out the success column as a numpy array\n",
    "    file = file.drop('SUCCESS', axis=1)  #remove the success column\n",
    "    file = removeFeatures(file)          #remove the features not being used\n",
    "    file = np.array(file)                #convert the data to a numpy array\n",
    "    return(file,labels)\n",
    "    \n",
    "training,trainingLabels = convert2np(training)\n",
    "testing,testingLabels = convert2np(testing)\n",
    "for each in DELETED_FEATURES:\n",
    "    featureNames.remove(each)\n",
    "featureNames.remove('SUCCESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to look at the shapes of the numpy arrays created - optional to run\n",
    "\n",
    "print('Training Features Shape:', training.shape)\n",
    "print('Training Labels Shape:', trainingLabels.shape)\n",
    "print('Testing Features Shape:', testing.shape)\n",
    "print('Testing Labels Shape:', testingLabels.shape)\n",
    "print(len(featureNames))\n",
    "print(featureNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create, run and evaluate the model\n",
    "\n",
    "#set logging file\n",
    "log = 'Features used: ' + str(featureNames) + '\\r\\n'\n",
    "\n",
    "#function to calculate metrics\n",
    "def calcResults(set, labels):\n",
    "    # Use the predict method on the training and test data\n",
    "    predictions = rf.predict(set)\n",
    "    # Calculate the number of errors\n",
    "    numberErrors = sum(abs(predictions - labels))\n",
    "\n",
    "    # Calculate and display accuracy and other statistics\n",
    "    accuracy = (1-(numberErrors/len(set)))*100\n",
    "    aucResult = metrics.roc_auc_score(labels, predictions)\n",
    "    cMatrix = metrics.confusion_matrix(labels, predictions)\n",
    "\n",
    "    return(accuracy, aucResult, cMatrix)\n",
    "\n",
    "\n",
    "#define characteristics for the learner\n",
    "n_estimators = 1000\n",
    "max_features = 'auto' #default is 'auto' which considers sqrt(n_features) at each split - alt are 1 to consider n_features or a decimal\n",
    "max_depth = 20    #default is 'None'\n",
    "min_samples_split = 150 #default is 2\n",
    "min_samples_leaf = 1  #default is 1\n",
    "random_state = 26 #default is 'None' but use a number for testing variations\n",
    "\n",
    "log += ' n_estimators: %s \\r\\n max_features: %s \\r\\n max_depth: %s \\r\\n min_samples_split: %s \\r\\n min_samples_leaf: %s \\r\\n' % (n_estimators,max_features,max_depth,min_samples_split,min_samples_leaf)\n",
    "\n",
    "#define parameter being tested and the variations on the parameter being tested\n",
    "charBeingVaried = 'min_samples_leaf'\n",
    "variations = [2,3,4,5,10,15]\n",
    "\n",
    "for variation in variations:  \n",
    "    \n",
    "    log += 'Running model with %s set to %s.\\r\\n' % (charBeingVaried,variation)\n",
    "    \n",
    "    min_samples_leaf = variation    #when running multiple criterion, replace null with characteristic being varied\n",
    "    \n",
    "    # Instantiate model with n_estimators decision trees\n",
    "    rf = sk.ensemble.RandomForestClassifier(criterion = 'gini', n_estimators = n_estimators, max_features = max_features, max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf, random_state = random_state)\n",
    "\n",
    "    # criterion = 'gini' or 'entropy'\n",
    "\n",
    "    # Train the model on training data\n",
    "    rf.fit(training, trainingLabels);\n",
    "\n",
    "    #run predictions on the training set and the test set and calculate metrics\n",
    "\n",
    "    accuracy, aucResult, cMatrix = calcResults(training, trainingLabels)\n",
    "\n",
    "    log += 'Train Set Accuracy: %s \\r\\n' %  round(accuracy, 2)\n",
    "    log += 'Train set AUC: %s  \\r\\n' % round(aucResult, 4)\n",
    "\n",
    "    accuracy, aucResult, cMatrix = calcResults(testing, testingLabels)\n",
    "\n",
    "    log += 'Test Set Accuracy: %s \\r\\n' %  round(accuracy, 2)\n",
    "    log += 'Test set AUC: %s  \\r\\n' % round(aucResult, 4)\n",
    "    log += '\\r\\n'\n",
    "\n",
    "    # Print out the confusion matrix.\n",
    "    print(variation)\n",
    "    print('accuracy: %s' % round(accuracy, 2))\n",
    "    print(cMatrix)\n",
    "    \n",
    "# Get numerical feature importances \n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 6)) for feature, importance in zip(featureNames, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "#[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]\n",
    "for pair in feature_importances:\n",
    "    log += 'Variable: {:20} Importance: {}\\r\\n'.format(*pair)\n",
    "    \n",
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the log file to LOG.txt\n",
    "\n",
    "with open('LOG.txt', 'w', newline='') as f:\n",
    "    f.write(log)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
