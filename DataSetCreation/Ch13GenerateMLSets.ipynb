{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copyright April 1, 2018, Warren E. Agin\n",
    "#Code released under the Creative Commons Attribution-NonCommercial-\n",
    "#ShareAlike 4.0 International License. You may obtain a copy of the license at \n",
    "#https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Script to generate training and test sets from Ch13TrimmedExtract.csv\n",
    "Exports sets as comma delimited csv files, and an additional text file with information needed to regularize and normalize prediction data'''\n",
    "\n",
    "#this section sets the initial variables to be used in the script\n",
    "\n",
    "#set number of datapoints used for the training set and the test set\n",
    "trainingSetSize=420000.00\n",
    "testSetSize=30000.00\n",
    "\n",
    "#columns used from the initial data set (first column is 0)\n",
    "colsUsed =[4,6,19,20,23,31,37,49,50,53,54,59,60,69,71,84]   #last column of original set is 83 - 84 is for success\n",
    "\n",
    "#initialize Readme file\n",
    "readme=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section opens the full data file, extracts the needed fields, identifies the size of the full data file,\n",
    "#and extracts information needed to build the raw training and test sets\n",
    "\n",
    "dataFile = open('CH13TrimmedExtract.csv', 'r+', newline='')\n",
    "reader = csv.reader(dataFile, delimiter=',')\n",
    "\n",
    "#determine number of datapoints in dataFile\n",
    "dataSetSize = float(len(list(reader)))\n",
    "\n",
    "readme = \"Working with a data file of %s size. \\r\\n\" % dataSetSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section assigns lines to the raw training and test sets. Only data from the\n",
    "#needed columns in the full data set is used.\n",
    "\n",
    "#writes only the columns identified in the function\n",
    "def write(writer, row, columns):\n",
    "    revisedRow=[]\n",
    "    for col in columns:\n",
    "        revisedRow.append(row[col])\n",
    "    writer.writerow(revisedRow)\n",
    "\n",
    "successCount=0\n",
    "failureCount=0\n",
    "testCount=0\n",
    "\n",
    "#open export files\n",
    "trainingFile = open('rawTrainingFile.csv', 'w', newline='')\n",
    "trainWriter = csv.writer(trainingFile)\n",
    "testFile = open('rawTestFile.csv', 'w', newline='')\n",
    "testWriter = csv.writer(testFile)\n",
    "tempFile = open('tempFile.csv', 'w', newline='')\n",
    "tempFile.close()\n",
    "tempFile = open('tempFile.csv', 'r+', newline='')\n",
    "tempWriter = csv.writer(tempFile)\n",
    "\n",
    "#move rows to appropriate files\n",
    "headerCount=0\n",
    "dataFile.seek(0)\n",
    "for row in reader:\n",
    "    #header row added to top of training and test sets add success column at position\n",
    "    if headerCount==0:\n",
    "        row.append('SUCCESS')\n",
    "        write(trainWriter, row, colsUsed)\n",
    "        write(testWriter, row, colsUsed)\n",
    "        headerCount += 1\n",
    "        \n",
    "    #for the remaining rows, calculate success as 1 or 0, append it\n",
    "    #and write to test file, and then the training file on a 50/50 basis\n",
    "    else:\n",
    "        if row[69]=='13' and row[71] in ['A','B']:\n",
    "            row.append(1)\n",
    "        else:\n",
    "            row.append(0)\n",
    "        #fill out test set first\n",
    "        if testCount<testSetSize:\n",
    "            write(testWriter, row, colsUsed)\n",
    "            testCount += 1\n",
    "\n",
    "        #fill out training set with one half successes and one half failures\n",
    "        elif successCount + failureCount< trainingSetSize:\n",
    "            if successCount<(trainingSetSize/2) and row[84]==1:\n",
    "                write(trainWriter, row, colsUsed)\n",
    "                successCount += 1\n",
    "            if failureCount<(trainingSetSize/2) and row[84]==0:\n",
    "                write(trainWriter, row, colsUsed)\n",
    "                failureCount += 1   \n",
    "        #when training set is full end\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "#log the results            \n",
    "\n",
    "readme += \"successCount: %s \\r\\n\" % successCount\n",
    "readme += \"failureCount: %s \\r\\n\" % failureCount\n",
    "readme += \"trainingSetSize: %s \\r\\n\" % trainingSetSize\n",
    "readme += \"testCount: %s \\r\\n\" % testCount\n",
    "readme += \"testSetSize: %s \\r\\n\" % testSetSize    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the datafiles and delete the temp file\n",
    "dataFile.close()\n",
    "trainingFile.close()\n",
    "testFile.close()\n",
    "tempFile.close()\n",
    "os.remove(\"tempFile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section loads the raw training file into a dictionary and extracts data regarding the training file needed to generate the features\n",
    "\n",
    "#function to import the raw data files into a labeled dictionary\n",
    "def importAsDict(filename):\n",
    "    with open(filename, 'r+', newline='') as rawFile:\n",
    "        rawReader = csv.reader(rawFile, delimiter=',')\n",
    "        firstLine=0\n",
    "        content=[]\n",
    "        for row in rawReader:\n",
    "            if firstLine==0:\n",
    "                labels = row\n",
    "                firstLine+=1\n",
    "            else:\n",
    "                content.append(row)\n",
    "    content = np.ndarray.tolist(np.transpose(content))\n",
    "\n",
    "    #create the dictionary - note the number of fields is hard-coded \n",
    "    rawDict = dict()\n",
    "    for each in range(0,16):  #16 is the number of fields\n",
    "        rawDict[labels[each]] = content[each]\n",
    "    return(rawDict)\n",
    "\n",
    "#import the training file into a labelled dictionary        \n",
    "training = importAsDict('rawTrainingFile.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract needed characteristics from training file\n",
    "\n",
    "#compute medians for selected fields, excluding nulls, zeros and outliers where appropriate\n",
    "#note that outliers are those values outside 0.13% of values (based on 3 standard deviation range)\n",
    "def extractMedian(field, excludeZero, calcCutoff, cutoff): #excludeZero and calcCutoff are boolean\n",
    "    temp = [x for x in training[field] if x!=\"\"] #remove empty data from set\n",
    "    temp = [float(x) for x in temp]\n",
    "    if excludeZero:\n",
    "        temp = [x for x in temp if x>0]\n",
    "    if calcCutoff:\n",
    "        temp.sort(reverse=True)\n",
    "        cutoff=temp[round(float(len(temp))*.0013)]\n",
    "    temp = [x for x in temp if x<float(cutoff)]\n",
    "    median = st.median(temp)\n",
    "    return(int(median), cutoff)\n",
    "\n",
    "medianREALPROP, cutoffREALPROP = extractMedian('REALPROP',True,True,'0.0')\n",
    "medianPERSPROP, cutoffPERSPROP = extractMedian('PERSPROP',False,True,'0.0')\n",
    "medianUNSECPR, cutoffUNSECPR = extractMedian('UNSECPR',False,False,'336900.0') #336,900 was the unsecured debt limit for chapter 13 case in 2008\n",
    "medianUNSECNPR, cutoffUNSECNPR = extractMedian('UNSECNPR',False,False,'336900.0')\n",
    "medianAVGMNTHI, cutoffAVGMNTHI = extractMedian('AVGMNTHI',False,True,'0.0')\n",
    "medianAVGMNTHE, cutoffAVGMNTHE = extractMedian('AVGMNTHE',False,True,'0.0')\n",
    "\n",
    "readme += '\\r\\nThe median value and cutoff values for the following original data fields will be needed to calculate features for deployment.\\r\\n\\r\\n'\n",
    "readme += 'median value for REALPROP = %s; cutoff = %s \\r\\n' % (medianREALPROP, cutoffREALPROP)\n",
    "readme += 'median value for PERSPROP = %s; cutoff = %s \\r\\n' % (medianPERSPROP, cutoffPERSPROP)\n",
    "readme += 'median value for UNSECPR = %s; cutoff = %s \\r\\n' % (medianUNSECPR, cutoffUNSECPR)\n",
    "readme += 'median value for UNSECNPR = %s; cutoff = %s \\r\\n' % (medianUNSECNPR, cutoffUNSECNPR)\n",
    "readme += 'median value for AVGMNTHI = %s; cutoff = %s \\r\\n' % (medianAVGMNTHI, cutoffAVGMNTHI)\n",
    "readme += 'median value for AVGMNTHE = %s; cutoff = %s \\r\\n' % (medianAVGMNTHE, cutoffAVGMNTHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoff size for districts - districts with a number of datapoints below the cutoff will not be used as features\n",
    "#calculated using .95 confidence level, .05 confidence interval, .4 overall success rate, and trainingSetSize\n",
    "districtCutoff = int(round(368.7936/(1+(.921984/(.0025*trainingSetSize)))))\n",
    "\n",
    "#determine success ratio aggregated by district. Save in dictionary form for use in creating final training and test sets\n",
    "\n",
    "#import file of district codes as ordered dictionary with codes as key and district names as content\n",
    "with open('DistrictCodes.csv', 'r', newline='') as districtFile:\n",
    "    reader = csv.DictReader(districtFile, delimiter=',')\n",
    "    districtIndex = {}\n",
    "    for row in reader:\n",
    "        districtIndex=row\n",
    "\n",
    "readme += '\\r\\nThe sample size cutoff for districts is %s and will be needed for deployment, in conjunction with the success rate for the total training set\\r\\n' % districtCutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over training data against districtIndex, count total of successes and failures in each district, calculate success ratio,\n",
    "#and create new dictionary districtSuccess with district code as index and the success ratio for that district\n",
    "#as the content.\n",
    "\n",
    "#set default success rate and add to log\n",
    "avgSuccessRatio = .40\n",
    "\n",
    "readme += 'The success rate for the total training set is %s \\r\\n' % avgSuccessRatio\n",
    "\n",
    "#build the districtSuccess dictionary. Where the number of data points is under the sample cutoff size,\n",
    "#use the default success rate\n",
    "undersamples=0\n",
    "districtSuccess={}\n",
    "for dist in districtIndex:\n",
    "    successCount=0.0\n",
    "    totalCount=0.0\n",
    "    successRatio=0.0\n",
    "    for item in range(0,int(trainingSetSize)):\n",
    "        if str(dist)==str(training['DISTRICT'][item]):\n",
    "            totalCount+=1\n",
    "            if training['SUCCESS'][item]==\"1\":\n",
    "                successCount+=1\n",
    "    if successCount==0: successRatio=1.0\n",
    "    if totalCount==0: totalCount=1.0\n",
    "    if totalCount < districtCutoff:\n",
    "        distSuccessRatio = avgSuccessRatio\n",
    "        undersamples+=1\n",
    "    else:\n",
    "        distSuccessRatio=round(successCount/totalCount,4)\n",
    "    districtSuccess[dist]=distSuccessRatio\n",
    "\n",
    "#create csv file with district codes and district success rates for use in deploying model\n",
    "with open('DistrictSuccessRates.csv', 'w', newline='') as f:  \n",
    "    writer = csv.DictWriter(f, districtSuccess.keys(), delimiter=',')\n",
    "    writer.writeheader()\n",
    "    writer.writerow(districtSuccess)\n",
    "    \n",
    "readme += '\\r\\nA list of districts and their associated success ratios is saved in the file named DistrictSuccessRates.csv. %s districts had sample sizes under the cutoff size and were assigned the success rate for the total training set.\\r\\n' % undersamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This section transforms the raw training file into a the actual training file with the desired features\n",
    "#note that the raw training file is already imported into training, and SUCCESS result added.\n",
    "\n",
    "#function to assist in returning natural logs\n",
    "def returnLog(x):\n",
    "    return math.log(x if x>0 else 1)\n",
    "\n",
    "def buildFeatures(rawFile, setSize):\n",
    "    \n",
    "    #initialize new feature lists \n",
    "    rawFile['DISTSUCCESS']=[]\n",
    "    rawFile['FEEP']=[]\n",
    "    rawFile['FEEI']=[]\n",
    "    rawFile['FEEW']=[]\n",
    "    rawFile['REALPROPNULL']=[]\n",
    "    rawFile['REALPROPNONE']=[]\n",
    "    rawFile['REALPROPVALUE']=[]\n",
    "    rawFile['REALPROPVALUESQR']=[]\n",
    "    rawFile['REALPROPVALUELOG']=[]\n",
    "    rawFile['PERSPROPNULL']=[]\n",
    "    rawFile['PERSPROPVALUE']=[]\n",
    "    rawFile['PERSPROPVALUESQR']=[]\n",
    "    rawFile['PERSPROPVALUELOG']=[]\n",
    "    rawFile['UNSECNPRNULL']=[]\n",
    "    rawFile['UNSECNPRVALUE']=[]\n",
    "    rawFile['UNSECNPRVALUESQR']=[]\n",
    "    rawFile['UNSECNPRVALUELOG']=[]\n",
    "    rawFile['UNSECEXCESS']=[]\n",
    "    rawFile['UNSECPRNULL']=[]\n",
    "    rawFile['UNSECPRVALUE']=[]\n",
    "    rawFile['UNSECPRVALUESQR']=[]\n",
    "    rawFile['UNSECPRVALUELOG']=[]\n",
    "    rawFile['AVGMNTHINULL']=[]\n",
    "    rawFile['AVGMNTHIVALUE']=[]\n",
    "    rawFile['AVGMNTHIVALUESQR']=[]\n",
    "    rawFile['AVGMNTHIVALUELOG']=[]\n",
    "    rawFile['IEINDEX']=[]\n",
    "    rawFile['IEGAP']=[]\n",
    "        \n",
    "    for row in range(0,int(setSize)):\n",
    "        \n",
    "        #build DISTSUCCESS and delete DISTRICT\n",
    "        if rawFile['DISTRICT'][row] in districtSuccess.keys():\n",
    "            rawFile['DISTSUCCESS'].append(districtSuccess[rawFile['DISTRICT'][row]])\n",
    "        else:\n",
    "            rawFile['DISTSUCCESS'].append(avgSuccessRatio)\n",
    "        \n",
    "        #convert NTRDBT to integers\n",
    "        if rawFile['NTRDBT'][row] == \"b\": rawFile['NTRDBT'][row]=int(1)\n",
    "        else: rawFile['NTRDBT'][row]=int(0)\n",
    "            \n",
    "        #convert JOINT to integers\n",
    "        if rawFile['JOINT'][row] == \"y\": rawFile['JOINT'][row]=int(1)\n",
    "        else: rawFile['JOINT'][row]=int(0)\n",
    "            \n",
    "        #convert ORGD1FPRSE to integers\n",
    "        if rawFile['ORGD1FPRSE'][row] == \"y\": rawFile['ORGD1FPRSE'][row]=int(1)\n",
    "        else: rawFile['ORGD1FPRSE'][row]=int(0)  \n",
    "            \n",
    "        #convert PRFILE to integers\n",
    "        if rawFile['PRFILE'][row] == \"y\": rawFile['PRFILE'][row]=int(1)\n",
    "        else: rawFile['PRFILE'][row]=int(0)\n",
    "            \n",
    "        #build FEEP, FEEI, FEEW and delete ORGFEESTS\n",
    "        if rawFile['ORGFEESTS'][row] == 'u': rawFile['FEEP'].append(int(1))\n",
    "        else: rawFile['FEEP'].append(int(0))\n",
    "        if rawFile['ORGFEESTS'][row] == 'i': rawFile['FEEI'].append(int(1))\n",
    "        else: rawFile['FEEI'].append(int(0))     \n",
    "        if rawFile['ORGFEESTS'][row] == 'w': rawFile['FEEW'].append(int(1))\n",
    "        else: rawFile['FEEW'].append(int(0)) \n",
    "        \n",
    "        #build REALPROPNULL, REALPROPNONE, REALPROPVALUE, REALPROPVALUESQR and REALPROPVALUELOG\n",
    "        #and delete REALPROP\n",
    "        if rawFile['REALPROP'][row] == \"\" or rawFile['REALPROP'][row]==None:\n",
    "            rawFile['REALPROPNULL'].append(int(1))\n",
    "            rawFile['REALPROPNONE'].append(int(0))\n",
    "            rawFile['REALPROPVALUE'].append(medianREALPROP)\n",
    "        elif rawFile['REALPROP'][row] == '0':\n",
    "            rawFile['REALPROPNULL'].append(int(0))\n",
    "            rawFile['REALPROPNONE'].append(int(1))\n",
    "            rawFile['REALPROPVALUE'].append(0.0)\n",
    "        elif float(rawFile['REALPROP'][row]) > cutoffREALPROP:\n",
    "            rawFile['REALPROPNULL'].append(int(0))\n",
    "            rawFile['REALPROPNONE'].append(int(0))\n",
    "            rawFile['REALPROPVALUE'].append(medianREALPROP)\n",
    "        else:\n",
    "            rawFile['REALPROPNULL'].append(int(0))\n",
    "            rawFile['REALPROPNONE'].append(int(0))\n",
    "            rawFile['REALPROPVALUE'].append(float(rawFile['REALPROP'][row]))\n",
    "        rawFile['REALPROPVALUESQR'].append(rawFile['REALPROPVALUE'][row]**2)\n",
    "        rawFile['REALPROPVALUELOG'].append(round(returnLog(rawFile['REALPROPVALUE'][row]),4))\n",
    "        \n",
    "        #build PERSPROPNULL, PERSPROPVALUE, PERSPROPVALUESQR and PERSPROPVALUELOG\n",
    "        #and delete PERSPROP\n",
    "        \n",
    "        if rawFile['PERSPROP'][row] == \"\" or rawFile['PERSPROP'][row]==None:\n",
    "            rawFile['PERSPROPNULL'].append(int(1))\n",
    "            rawFile['PERSPROPVALUE'].append(medianPERSPROP)\n",
    "        elif float(rawFile['PERSPROP'][row]) > cutoffPERSPROP:\n",
    "            rawFile['PERSPROPNULL'].append(int(0))\n",
    "            rawFile['PERSPROPVALUE'].append(medianPERSPROP)\n",
    "        else:\n",
    "            rawFile['PERSPROPNULL'].append(int(0))\n",
    "            rawFile['PERSPROPVALUE'].append(float(rawFile['PERSPROP'][row]))\n",
    "        rawFile['PERSPROPVALUESQR'].append(rawFile['PERSPROPVALUE'][row]**2)\n",
    "        rawFile['PERSPROPVALUELOG'].append(round(returnLog(rawFile['PERSPROPVALUE'][row]),4))\n",
    "       \n",
    "        #build UNSECNPRNULL, UNSECNPRVALUE, UNSECNPRVALUESQR and UNSECNPRVALUELOG\n",
    "        #and delete UNSECNPR\n",
    "        \n",
    "        if rawFile['UNSECNPR'][row] == \"\" or rawFile['UNSECNPR'][row]==None:\n",
    "            rawFile['UNSECNPRNULL'].append(int(1))\n",
    "            rawFile['UNSECNPRVALUE'].append(medianUNSECNPR)\n",
    "        elif float(rawFile['UNSECNPR'][row]) > float(cutoffUNSECNPR):\n",
    "            rawFile['UNSECNPRNULL'].append(int(0))\n",
    "            rawFile['UNSECNPRVALUE'].append(medianUNSECNPR)\n",
    "        else:\n",
    "            rawFile['UNSECNPRNULL'].append(int(0))\n",
    "            rawFile['UNSECNPRVALUE'].append(float(rawFile['UNSECNPR'][row]))\n",
    "        rawFile['UNSECNPRVALUESQR'].append(rawFile['UNSECNPRVALUE'][row]**2)\n",
    "        rawFile['UNSECNPRVALUELOG'].append(round(returnLog(rawFile['UNSECNPRVALUE'][row]),4))       \n",
    "         \n",
    "        #build UNSECPRNULL, UNSECPRVALUE, UNSECPRVALUESQR and UNSECPRVALUELOG\n",
    "        #and delete UNSECPR\n",
    "        \n",
    "        if rawFile['UNSECPR'][row] == \"\" or rawFile['UNSECPR'][row]==None:\n",
    "            rawFile['UNSECPRNULL'].append(int(1))\n",
    "            rawFile['UNSECPRVALUE'].append(medianUNSECPR)\n",
    "        elif float(rawFile['UNSECPR'][row]) > float(cutoffUNSECPR):\n",
    "            rawFile['UNSECPRNULL'].append(int(0))\n",
    "            rawFile['UNSECPRVALUE'].append(medianUNSECPR)\n",
    "        else:\n",
    "            rawFile['UNSECPRNULL'].append(int(0))\n",
    "            rawFile['UNSECPRVALUE'].append(float(rawFile['UNSECPR'][row]))\n",
    "        rawFile['UNSECPRVALUESQR'].append(rawFile['UNSECPRVALUE'][row]**2)\n",
    "        rawFile['UNSECPRVALUELOG'].append(round(returnLog(rawFile['UNSECPRVALUE'][row]),4))        \n",
    "              \n",
    "        #build UNSECEXCESS\n",
    "        if rawFile['UNSECPR'][row] == \"\" or rawFile['UNSECPR'][row]==None:\n",
    "            priority=0.0\n",
    "        else: priority=float(rawFile['UNSECPR'][row])\n",
    "        if rawFile['UNSECNPR'][row] == \"\" or rawFile['UNSECNPR'][row]==None:\n",
    "            unsecured=0.0\n",
    "        else: unsecured=float(rawFile['UNSECNPR'][row])\n",
    "        if unsecured+priority > float(cutoffUNSECNPR):\n",
    "            rawFile['UNSECEXCESS'].append(int(1))\n",
    "        else: rawFile['UNSECEXCESS'].append(int(0))\n",
    "        \n",
    "        #build AVGMNTHINULL, AVGMNTHIVALUE, AVGMNTHIVALUESQR and AVGMNTHIVALUELOG\n",
    "        #and delete AVGMNTHI\n",
    "        \n",
    "        if rawFile['AVGMNTHI'][row] == \"\" or rawFile['AVGMNTHI'][row]==None:\n",
    "            rawFile['AVGMNTHINULL'].append(int(1))\n",
    "            rawFile['AVGMNTHIVALUE'].append(medianAVGMNTHI)\n",
    "        elif float(rawFile['AVGMNTHI'][row]) > float(cutoffAVGMNTHI):\n",
    "            rawFile['AVGMNTHINULL'].append(int(0))\n",
    "            rawFile['AVGMNTHIVALUE'].append(medianAVGMNTHI)\n",
    "        else:\n",
    "            rawFile['AVGMNTHINULL'].append(int(0))\n",
    "            rawFile['AVGMNTHIVALUE'].append(float(rawFile['AVGMNTHI'][row]))\n",
    "        rawFile['AVGMNTHIVALUESQR'].append(rawFile['AVGMNTHIVALUE'][row]**2)\n",
    "        rawFile['AVGMNTHIVALUELOG'].append(round(returnLog(rawFile['AVGMNTHIVALUE'][row]),4))  \n",
    "        \n",
    "        #build IENDEX - uses AVGMNTHIVALUE from above, and expense\n",
    "        if rawFile['AVGMNTHE'][row] == \"\" or rawFile['AVGMNTHE'][row]==None:\n",
    "            expense =float(medianAVGMNTHI)\n",
    "        elif float(rawFile['AVGMNTHE'][row]) > float(cutoffAVGMNTHE):\n",
    "            expense =float(medianAVGMNTHI)\n",
    "        else: expense = float(rawFile['AVGMNTHE'][row])    \n",
    "        rawFile['IEINDEX'].append(round(float(max(.1,float(rawFile['AVGMNTHIVALUE'][row]))/max(.1,expense)),4))\n",
    "        \n",
    "        #build IEGAP - uses AVGMNTHIVALUE from above, and expense\n",
    "        rawFile['IEGAP'].append(float(rawFile['AVGMNTHIVALUE'][row])-(expense))\n",
    "    \n",
    "    #delete depreciated fields\n",
    "    for each in ['CASEKEY','CLCHPT','D1FDSP','DISTRICT','ORGFEESTS','REALPROP','PERSPROP','UNSECNPR','UNSECPR','AVGMNTHI','AVGMNTHE']: \n",
    "        if each in rawFile:\n",
    "            del rawFile[each]\n",
    "\n",
    "    return(rawFile)\n",
    "\n",
    "#run buildFeatures to transform the training file\n",
    "training = buildFeatures(training, trainingSetSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the column features into a csv file for use by the learner and in deployment, along with a csv with the names of the column features\n",
    "with open('featureNames.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, training.keys(), delimiter=',')\n",
    "    writer.writeheader()\n",
    "\n",
    "\n",
    "def writeFeatures(file, filename, setSize):\n",
    "    with open(filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for row in range(0,int(setSize)):\n",
    "            set=[]\n",
    "            for key in file.keys():\n",
    "                set.append(str(file[key][row]))\n",
    "            writer.writerow(set)\n",
    "    return()\n",
    "\n",
    "writeFeatures(training, 'trainingFile.csv', trainingSetSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat the steps using the prepared functions to import the raw test data, convert it to include the required features,\n",
    "#and write the final test file for use by the learner\n",
    "\n",
    "test = importAsDict('rawTestFile.csv')\n",
    "#test = addSuccess(test, testSetSize)\n",
    "test = buildFeatures(test, testSetSize)\n",
    "writeFeatures(test, 'testFile.csv', testSetSize)\n",
    "\n",
    "readme += '\\r\\nThe training data file is named trainingFile.csv, the test data file is named testData.csv, and an ordered list of feature names is in the file named featureNames.csv\\r\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the raw files\n",
    "\n",
    "os.remove('rawTrainingFile.csv')\n",
    "os.remove('rawTestFile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the readme file to LEARNER_README.txt\n",
    "\n",
    "with open('LEARNER_README.txt', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    readme=[readme]\n",
    "    writer.writerow(readme)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
